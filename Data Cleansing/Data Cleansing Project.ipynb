{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining, Cleaning and Normalizing Data\n",
    "## Indian Health Service \n",
    "\n",
    "#### Tribes\n",
    "According to the National Congress of American Indians, there are approximately 573 federally recognized Indian Nations (interchangeably called tribes, nations, bands, pueblos, communities and native villages) in the United States <sup> 1</sup>. Nearly 40% (229) are located in the state of Alaska, while the others are located in 35 other states. Each Nation is ethnically, culturally and linguistically diverse with its own unique history<sup>1</sup>. \n",
    "\n",
    "#### Indian Health Service\n",
    "The goal of the Indian Health Service (IHS), is to provide federally funded health service to American Indians and/or Alaska Natives. The National Patient Information Reporting System (NPIRS), instituted the National Data Warehouse (NDW). The NDW is a data warehouse environment specifically for the Indian Health Service's (IHS) national data repository<sup> 2</sup>. Within this repository is information regarding various levels of patient care. https://www.ihs.gov/ndw/\n",
    "\n",
    "#### Standard Codebook\n",
    "Looking deeper within the NDW are tables with the approved codes sets from the Indian Health Service (IHS) Standard Code Book (SCB). The Standard Code Book is a uniform listing of descriptive terms and codes for the purpose of recording/reporting medical information collected during the provision of health care services. One of the tables is named \"Community\". A community is an area in which a tribe, is known to reside. It is not designated by coordinates. Because of this, it is difficult to determine where a community may be. \n",
    "\n",
    "#### Goal of Project\n",
    "The goal of this project is to associate Indian Health Service communities to a Geographic Names Information System (GNIS) location. The Indian Health Service (IHS) consists of 14,770 unique active and inactive communities. This project also demonstrates some of the most tedious part of preparing datasets for exploration which are data cleansing and normalization-also called munging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Information Names System (GNIS)\n",
    "The Geographic Names Information System (GNIS) is the federal and national standard for geographic nomenclature.<sup> 3</sup> The U.S. Geological Survey developed the GNIS in support of the U.S. Board on Geographic Names as the official repository of domestic geographic names data, the official vehicle for geographic names use by all departments of the Federal Government, and the source for applying geographic names to federal electronic and printed products <sup> 3</sup>. The GNIS download consists of 2,279,278 locations within the United States as a text file. There are also individual state text files for usage. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1: Geographic Names Information Systems (GNIS) columns\n",
    "\n",
    "| Name                  | Type      | \n",
    "|-----------------------|-----------|\n",
    "| Feature Name          | Number    |\n",
    "| Feature Class         | Character |\n",
    "| State Alpha           | Character |\n",
    "| State Numeric         | Character |\n",
    "| County Name           | Character |\n",
    "| County Numeric        | Character |\n",
    "| Primary Latitude DMS  | Character |\n",
    "| Primary Longitude DMS | Character |\n",
    "| Primary Latitude DEC  | Number    |\n",
    "| Primary Longitude DEC | Number    |   \n",
    "| Elevation (meters)    | Number    |\n",
    "| Source Latitude DMS   | Character |\n",
    "| Source Longitude DMS  | Character |\n",
    "| Source Latitude DEC   | Number    |\n",
    "| Source Longitude DEC  | Number    |                                 \n",
    "| Elevation (feet)      | Number    |\n",
    "| Map Name              | Character |\n",
    "| Date Created          | Date      |\n",
    "| Date Edited           | Date      |\n",
    "\n",
    "\n",
    "Table 2: Community table from Indian Health Service Standard Codebook\n",
    "\n",
    "| Name      | Type      |\n",
    "|-----------|-----------|\n",
    "| Code      | Number    |\n",
    "| State     | Character |\n",
    "| County    | Character |\n",
    "| Community | Character |\n",
    "| ASU Code  | Number    |\n",
    "| Status    | Character |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Files\n",
    "\n",
    "A copy of The Indian Health Service communities was downloaded from the standard codebook in excel file format: https://www.ihs.gov/scb/index.cfm?module=W_COMMUNITY&option=list&num=84&newquery=1\n",
    "\n",
    "As well as a copy of the GNIS locations in text file format (NationalFile_20181201.zip):\n",
    "https://geonames.usgs.gov/domestic/download_data.htm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Normalization\n",
    "The data was normalized by converting the columns of interest to string format for easier data handling, stripped of leading and trailing whitespaces and applied uppercase lettering. Inactive communities and unknown locations were excluded from this analysis. The same process was completed for the GNIS file for columns: ‘COUNTY_NUMERIC’, ‘STATE_NUMERIC’, ‘FEATURE_NAME’ and ‘FEATURE_CLASS’. The assumption is the Community column in the IHS standard codebook should be similar or identical to the FEATURE_NAME column in the GNIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14769, 6)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import fuzzymatcher  \n",
    "#Read in the IHS Communities File\n",
    "df1=pd.read_excel('Communities.xlsx')\n",
    "#Change Columns of interest to strings\n",
    "df1[['Code', 'State', 'County', 'Community', 'Status']] = df1[['Code', 'State', 'County', 'Community', 'Status']].astype(str)\n",
    "#Apply uppercase and strip leading and trailing whitespaces of all object columns\n",
    "df1 = df1.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "df1 = df1.apply(lambda x: x.str.upper() if x.dtype == \"object\" else x)\n",
    "#The code is the INCITS code, I am only interested in the state code at this time\n",
    "df1['Code'] = df1['Code'].str[0:2]\n",
    "#Checks to view result and counts...a must\n",
    "df1.head() \n",
    "#Checking the overall structure of the dataset\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2279278, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in the GNIS file\n",
    "df2=pd.read_csv('NationalFile_20181201.txt', \"|\")\n",
    "#Change Columns of interest to strings\n",
    "df2[['COUNTY_NUMERIC', 'STATE_NUMERIC', 'FEATURE_NAME', 'FEATURE_CLASS', 'STATE_ALPHA', 'COUNTY_NAME']] = df2[['COUNTY_NUMERIC', 'STATE_NUMERIC', 'FEATURE_NAME', 'FEATURE_CLASS', 'STATE_ALPHA', 'COUNTY_NAME']].astype(str)\n",
    "#Apply uppercase and strip leading and trailing whitespaces of all object columns\n",
    "df2 = df2.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "df2 = df2.apply(lambda x: x.str.upper() if x.dtype == \"object\" else x)\n",
    "#Checks to view result and counts...checking the FEATURE_NAME column given that it is of most interest at this time\n",
    "df2['FEATURE_NAME'] \n",
    "df2.head() \n",
    "#Looking for Unnamed Columns\n",
    "df2.loc[:,~df2.columns.str.contains('^Unnamed')]  \n",
    "#Checking the overall structure of the dataset\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown ",
   "metadata": {},
   "source": [
    "Inner Merge\n",
    "Once the data in both datasets were normalized, an inner merge was performed on State Code (Code), Community, STATE_NUMERIC and FEATURE_NAME and saved in a dataframe (df3). After the merge, duplicates were dropped based upon state and Community name. Then communities were identified that were not included in this merge due to spelling differences between IHS and GNIS datasets. The merged output was then placed into a separate dataframe (df4). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging/Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9734, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging IHS dataset to GNIS dataset based on the two digit State Code and Name\n",
    "df3=pd.merge(df1,df2, how='inner', left_on=['Code','Community'],right_on=['STATE_NUMERIC','FEATURE_NAME'])  \n",
    "df3.shape  \n",
    "#Drop duplicates after initial merge (there are many locations in the United States that have identical names, \n",
    "#only interested in locations within the same state as a quality check)\n",
    "df4=df3.sort_values('Community').drop_duplicates(subset=['Code','Community'],keep='first')  \n",
    "df4.loc[:,~df4.columns.str.contains('^Unnamed')]  \n",
    "df4.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identitfy Residuals\n",
    "\n",
    "The communities identified that were not included in the merge were classified as “residuals”.  These residuals were placed into a dataframe (df5) to isolate them from the rest of the data to be used for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4055, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=df1[~df1['Community'].isin(df4['FEATURE_NAME'])]  \n",
    "df5.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Code State              County           Community ASU Code    Status\n",
       "0       01    AL             BALDWIN         BAY MINETTE     5874    ACTIVE\n",
       "1       01    AL             BALDWIN              DAPHNE     5874    ACTIVE\n",
       "3       01    AL             BALDWIN            FAIRHOPE     5874    ACTIVE\n",
       "5       01    AL             BALDWIN         ROBERTSDALE     5874    ACTIVE\n",
       "7       01    AL             BALDWIN          SUMMERDALE     5874    ACTIVE\n",
       "8       01    AL             BALDWIN          SILVERHILL     5874    ACTIVE\n",
       "9       01    AL             BALDWIN             PERDIDO     5874    ACTIVE\n",
       "10      01    AL             BALDWIN              LOXLEY     5874    ACTIVE\n",
       "11      01    AL             BALDWIN         GULF SHORES     5874    ACTIVE\n",
       "12      01    AL             BALDWIN        ORANGE BEACH     5874    ACTIVE\n",
       "14      01    AL             BALDWIN             LILLIAN     5874    ACTIVE\n",
       "15      01    AL             BALDWIN        SPANISH FORT     5874    ACTIVE\n",
       "17      01    AL             BALDWIN           STAPLETON     5874    ACTIVE\n",
       "18      01    AL              BUTLER            MCKENZIE     5800    ACTIVE\n",
       "20      01    AL             CONECUH              REPTON     5800    ACTIVE\n",
       "21      01    AL              DEKALB          RAINSVILLE     5800    ACTIVE\n",
       "22      01    AL            ESCAMBIA             BREWTON     5874    ACTIVE\n",
       "23      01    AL            ESCAMBIA       EAST ESCAMBIA     5874    ACTIVE\n",
       "24      01    AL            ESCAMBIA            FLOMATON     5874    ACTIVE\n",
       "25      01    AL            ESCAMBIA        MCCULLOUG-HU     5874    ACTIVE\n",
       "26      01    AL            ESCAMBIA             HUXFORD     5874    ACTIVE\n",
       "27      01    AL            ESCAMBIA        EAST BREWTON     5874    ACTIVE\n",
       "28      01    AL            ESCAMBIA              ATMORE     5874    ACTIVE\n",
       "29      01    AL              MOBILE        BAYOU LA BAT     5874    ACTIVE\n",
       "30      01    AL              MOBILE          CITRONELLA     5874    ACTIVE\n",
       "31      01    AL              MOBILE           GRAND BAY     5874    ACTIVE\n",
       "32      01    AL              MOBILE              MOBILE     5874    ACTIVE\n",
       "34      01    AL              MOBILE              SEMMES     5874    ACTIVE\n",
       "35      01    AL              MOBILE        TANNER-WILLM     5874    ACTIVE\n",
       "36      01    AL              MOBILE            THEODORE     5874    ACTIVE\n",
       "...    ...   ...                 ...                 ...      ...       ...\n",
       "14679   55    WI   WISCONSIN UNKNOWN        WISCONSN UNK     1100  INACTIVE\n",
       "14680   55    WI   WISCONSIN UNKNOWN        WISCONSN UNK     1100  INACTIVE\n",
       "14694   56    WY             FREMONT        BOULDER FLAT     4046    ACTIVE\n",
       "14697   56    WY             FREMONT        DRY CREEK RA     4046    ACTIVE\n",
       "14700   56    WY             FREMONT         FT WASHAKIE     4046    ACTIVE\n",
       "14708   56    WY             FREMONT         ST STEPHENS     4046    ACTIVE\n",
       "14714   56    WY         HOT SPRINGS        HAMILTON DOM     4046    ACTIVE\n",
       "14722   56    WY             NATRONA             BARNUNN     4000    ACTIVE\n",
       "14746   56    WY         WYOMING UNK         WYOMING UNK     4000    ACTIVE\n",
       "14747   56    WY         WYOMING UNK         WYOMING UNK     4000  INACTIVE\n",
       "14748   56    WY         WYOMING UNK         WYOMING UNK     4000  INACTIVE\n",
       "14750   72    PR     PUERTO RICO UNK     PUERTO RICO UNK     9999    ACTIVE\n",
       "14751   72    PR     PUERTO RICO UNK        PUERTO R UNK     5800  INACTIVE\n",
       "14752   72    PR     PUERTO RICO UNK        PUERTO R UNK     5800  INACTIVE\n",
       "14753   78    VI  VIRGIN ISLANDS UNK  VIRGIN ISLANDS UNK     9999    ACTIVE\n",
       "14754   78    VI  VIRGIN ISLANDS UNK        VIRGIN I UNK     5800  INACTIVE\n",
       "14755   78    VI  VIRGIN ISLANDS UNK        VIRGIN I UNK     5800  INACTIVE\n",
       "14756   95    NL     NETHERLANDS UNK     NETHERLANDS UNK     9999    ACTIVE\n",
       "14757   96    CA          CANADA UNK            CORNWALL     5800    ACTIVE\n",
       "14758   96    CA          CANADA UNK     CORNWALL ISLAND     5800    ACTIVE\n",
       "14759   96    CA          CANADA UNK                SNYE     5800    ACTIVE\n",
       "14760   96    CA          CANADA UNK           ST. REGIS     5800    ACTIVE\n",
       "14761   96    CA          CANADA UNK          CANADA UNK     9999    ACTIVE\n",
       "14762   96    CA          CANADA UNK          CANADA UNK     9999  INACTIVE\n",
       "14763   96    CA          CANADA UNK          CANADA UNK     9999  INACTIVE\n",
       "14764   97    MX          MEXICO UNK          MEXICO UNK     9999    ACTIVE\n",
       "14765   97    MX          MEXICO UNK          MEXICO UNK     9999  INACTIVE\n",
       "14766   97    MX          MEXICO UNK          MEXICO UNK     9999  INACTIVE\n",
       "14767   98   NAN         UNSPECIFIED         UNSPECIFIED     9999  INACTIVE\n",
       "14768   99     ?             UNKNOWN             UNKNOWN     9999    ACTIVE\n",
       "\n",
       "[4055 rows x 6 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy Matching\n",
    "A fuzzy match was performed on the residuals with a python package named “fuzzymatcher”, and saved in a dataframe (df6).The goal of this package is to match two dataframes based upon one or two similar fields. A fuzzy match was performed on Community and FEATURE_NAME. After matches are identified, the package ranks each record by probabilistic scoring. Duplicate records were excluded by both state and Community name so that only unique matches by state were included in the final output. Any excluded community was classified as a residual. \n",
    "This is the ink to Github repository for the fuzzymatcher package: https://github.com/RobinL/fuzzymatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4055, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will take some time to run-not the most efficient method on a dataset this size\n",
    "df6=fuzzymatcher.fuzzy_left_join(df5,df2,left_on=\"Community\", right_on=\"FEATURE_NAME\")  \n",
    "df6.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_match_score</th>\n",
       "      <th>__id_left</th>\n",
       "      <th>__id_right</th>\n",
       "      <th>Code</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Community</th>\n",
       "      <th>ASU Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>FEATURE_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>PRIM_LONG_DEC</th>\n",
       "      <th>SOURCE_LAT_DMS</th>\n",
       "      <th>SOURCE_LONG_DMS</th>\n",
       "      <th>SOURCE_LAT_DEC</th>\n",
       "      <th>SOURCE_LONG_DEC</th>\n",
       "      <th>ELEV_IN_M</th>\n",
       "      <th>ELEV_IN_FT</th>\n",
       "      <th>MAP_NAME</th>\n",
       "      <th>DATE_CREATED</th>\n",
       "      <th>DATE_EDITED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437734</td>\n",
       "      <td>0_left</td>\n",
       "      <td>78409_right</td>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "      <td>BALDWIN</td>\n",
       "      <td>BAY MINETTE</td>\n",
       "      <td>5874</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>113588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.773047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>BAY MINETTE NORTH</td>\n",
       "      <td>09/04/1980</td>\n",
       "      <td>08/16/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.315869</td>\n",
       "      <td>1_left</td>\n",
       "      <td>121385_right</td>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "      <td>BALDWIN</td>\n",
       "      <td>DAPHNE</td>\n",
       "      <td>5874</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>157933.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.903605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>DAPHNE</td>\n",
       "      <td>09/04/1980</td>\n",
       "      <td>12/06/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.323311</td>\n",
       "      <td>2_left</td>\n",
       "      <td>82920_right</td>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "      <td>BALDWIN</td>\n",
       "      <td>FAIRHOPE</td>\n",
       "      <td>5874</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>118120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.903326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>DAPHNE</td>\n",
       "      <td>09/04/1980</td>\n",
       "      <td>08/27/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.368564</td>\n",
       "      <td>3_left</td>\n",
       "      <td>90480_right</td>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "      <td>BALDWIN</td>\n",
       "      <td>ROBERTSDALE</td>\n",
       "      <td>5874</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>125703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.711932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>ROBERTSDALE</td>\n",
       "      <td>09/04/1980</td>\n",
       "      <td>03/20/2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.358645</td>\n",
       "      <td>4_left</td>\n",
       "      <td>118725_right</td>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "      <td>BALDWIN</td>\n",
       "      <td>SUMMERDALE</td>\n",
       "      <td>5874</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>155262.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.699709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>FOLEY</td>\n",
       "      <td>09/04/1980</td>\n",
       "      <td>03/20/2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     best_match_score __id_left    __id_right Code State   County  \\\n",
       "0            0.437734    0_left   78409_right   01    AL  BALDWIN   \n",
       "26           0.315869    1_left  121385_right   01    AL  BALDWIN   \n",
       "51           0.323311    2_left   82920_right   01    AL  BALDWIN   \n",
       "101          0.368564    3_left   90480_right   01    AL  BALDWIN   \n",
       "122          0.358645    4_left  118725_right   01    AL  BALDWIN   \n",
       "\n",
       "       Community ASU Code  Status  FEATURE_ID     ...      PRIM_LONG_DEC  \\\n",
       "0    BAY MINETTE     5874  ACTIVE    113588.0     ...         -87.773047   \n",
       "26        DAPHNE     5874  ACTIVE    157933.0     ...         -87.903605   \n",
       "51      FAIRHOPE     5874  ACTIVE    118120.0     ...         -87.903326   \n",
       "101  ROBERTSDALE     5874  ACTIVE    125703.0     ...         -87.711932   \n",
       "122   SUMMERDALE     5874  ACTIVE    155262.0     ...         -87.699709   \n",
       "\n",
       "    SOURCE_LAT_DMS SOURCE_LONG_DMS SOURCE_LAT_DEC SOURCE_LONG_DEC ELEV_IN_M  \\\n",
       "0              NaN             NaN            NaN             NaN      82.0   \n",
       "26             NaN             NaN            NaN             NaN      49.0   \n",
       "51             NaN             NaN            NaN             NaN      37.0   \n",
       "101            NaN             NaN            NaN             NaN      44.0   \n",
       "122            NaN             NaN            NaN             NaN      34.0   \n",
       "\n",
       "    ELEV_IN_FT           MAP_NAME  DATE_CREATED  DATE_EDITED  \n",
       "0        269.0  BAY MINETTE NORTH    09/04/1980   08/16/2013  \n",
       "26       161.0             DAPHNE    09/04/1980   12/06/2013  \n",
       "51       121.0             DAPHNE    09/04/1980   08/27/2013  \n",
       "101      144.0        ROBERTSDALE    09/04/1980   03/20/2008  \n",
       "122      112.0              FOLEY    09/04/1980   03/20/2008  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1884, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keeping only state to state output\n",
    "df7 = df6[df6['State'] == df6['STATE_ALPHA']]  \n",
    "df7.shape  \n",
    "#Save only unique output and dropping duplicates\n",
    "df8=df7.sort_values('Community').drop_duplicates(subset=['Community','Code'],keep='first')  \n",
    "df8.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['best_match_score', '__id_left', '__id_right', 'Code', 'State',\n",
       "       'County', 'Community', 'ASU Code', 'Status', 'FEATURE_ID',\n",
       "       'FEATURE_NAME', 'FEATURE_CLASS', 'STATE_ALPHA', 'STATE_NUMERIC',\n",
       "       'COUNTY_NAME', 'COUNTY_NUMERIC', 'PRIMARY_LAT_DMS', 'PRIM_LONG_DMS',\n",
       "       'PRIM_LAT_DEC', 'PRIM_LONG_DEC', 'SOURCE_LAT_DMS', 'SOURCE_LONG_DMS',\n",
       "       'SOURCE_LAT_DEC', 'SOURCE_LONG_DEC', 'ELEV_IN_M', 'ELEV_IN_FT',\n",
       "       'MAP_NAME', 'DATE_CREATED', 'DATE_EDITED'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output after the fuzzy matching contains columns I do not want, so I simply deleted them. This was useful if I plan to do further matching in another method and would like to output my results to another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to see what columns are included in this dataframe before needing to delete\n",
    "df8.drop(['best_match_score','__id_left','__id_right'], axis=1, inplace=True)\n",
    "#Saving the results from initial match to a file\n",
    "df8.to_excel('Fuzzy Communities With Match_1.xlsx') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Further Residuals\n",
    "Locations that were not included in the first iteration of matches are to be identified here. Further matching on text is necessary to ensure the most locations are captured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=df6[df6['State'] != df6['STATE_ALPHA']]  \n",
    "df10=df9.sort_values('Community').drop_duplicates(subset=['Community','Code'],keep='first')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2035, 29)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion 2,035 IHS locations remain unlocated due to various reasons due to differences in spelling, the location existing in a neighboring state or simply not existing in both datasets. Further discovery is needed from this point forward. I hope you found this notebook useful especially when dealing with text data and joining two textual datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tribal Nations & the United States: An Introduction. Retrieved from http://www.ncai.org/about-tribeshttp://www.ncai.org/about-tribes. Accessed March 7, 2019\n",
    "\n",
    "2. Indian Health Service. The Federal Health Program for American Indians and Alaska Natives. https://www.ihs.gov/scb/index.cfm?module=W_COMMUNITY&option=list&num=84&newquery=1. Accessed March 7, 2019.\n",
    "\n",
    "3. Eastern Region Geography. Domestic and Antarctic Names - State and Topical Gazetteer Download Files. https://geonames.usgs.gov/domestic/download_data.htm. Accessed March 7, 2019. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
